# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1amJ1ts6vNhvb7L-2XA-xfEL-OJQC4ivy
"""

# ==========================================================
# 1. IMPORT LIBRARIES
# ==========================================================
import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.utils import resample

sns.set(style="whitegrid")

# ==========================================================
# 2. LOAD DATA
# ==========================================================
df = pd.read_csv("/content/drive/MyDrive/Statistical Analysis_Project/Consumer Preferences for Eco-labels in Short Supply Chains.csv")

# ==========================================================
# 3. CREATE ENVIRONMENTAL CONCERN (MEAN OF 8 ITEMS) & CREATE COMBINED PSYCHOLOGICAL ATTITUDE
# ==========================================================
env_items = [
    "No deforestation",
    "natural resources protecting",
    "recyclable packaging",
    "reduced use of energy",
    "low carbon emissions",
    "reduced use of pesticides/fertilizers",
    "water sparingly",
    "familiarity"
]

df["EnvConcern"] = df[env_items].mean(axis=1)

psych_vars = ["trust", "satisfaction", "feelings"]
df["PsychAttitude"] = df[psych_vars].mean(axis=1)

# ==========================================================
# 4. DEFINE PREDICTORS
# ==========================================================
predictors = [
    "EnvConcern",
    "PsychAttitude",
    "Gen",
    "Age of children in family",
    "Edu"
]

psy_vars = ["EnvConcern", "PsychAttitude"]

# ==========================================================
# 5. FUNCTION: RUN OLS REGRESSION
# ==========================================================
def run_ols(df, y_var, predictors):
    y = df[y_var]
    X = sm.add_constant(df[predictors])
    model = sm.OLS(y, X).fit()
    print(f"\n===== OLS Regression Results for {y_var.upper()} =====")
    print(model.summary())
    return model

# ==========================================================
# 6. FUNCTION: CALCULATE STANDARDIZED BETAS (OLS)
# ==========================================================
def standardized_beta_ols(df, y_var, predictors):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df[predictors])
    y_scaled = scaler.fit_transform(df[[y_var]]).flatten()
    X_scaled = sm.add_constant(X_scaled)
    model = sm.OLS(y_scaled, X_scaled).fit()
    return pd.Series(model.params[1:], index=predictors)  # exclude intercept

# ==========================================================
# 7. FUNCTION: RUN LOGISTIC REGRESSION + IMBALANCE CHECK
# ==========================================================
def run_logistic(df, y_var, predictors):
    print(f"\n===== Checking imbalance for {y_var.upper()} =====")
    print(df[y_var].value_counts(normalize=True))

    # imbalance threshold
    imbalance_ratio = df[y_var].value_counts(normalize=True).max()

    # If imbalance > 60%, apply oversampling
    if imbalance_ratio > 0.60:
        print("\n⚠ Dataset Imbalanced → Applying Oversampling...\n")

        df_major = df[df[y_var] == df[y_var].value_counts().idxmax()]
        df_minor = df[df[y_var] != df[y_var].value_counts().idxmax()]

        df_minor_upsampled = resample(
            df_minor,
            replace=True,
            n_samples=len(df_major),
            random_state=42
        )

        # combine + reset index (FIX)
        df_balanced = pd.concat([df_major, df_minor_upsampled]).reset_index(drop=True)
    else:
        print("\nDataset is balanced → No correction applied.\n")
        df_balanced = df.copy().reset_index(drop=True)

    # ======================================================
    # LOGISTIC REGRESSION USING STATSMODELS
    # ======================================================
    X = df_balanced[predictors]
    y = df_balanced[y_var]

    # standardize predictors
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # convert scaled matrix → DataFrame with correct column names
    X_scaled_df = pd.DataFrame(X_scaled, columns=predictors)

    # add constant (intercept) with proper label "const"
    X_const = sm.add_constant(X_scaled_df, has_constant='add')

    # fit logistic model
    logit_model = sm.Logit(y, X_const).fit()

    print("\n===== Logistic Regression Summary =====")
    print(logit_model.summary())

    return logit_model, scaler

# ==========================================================
# 8. RUN MODELS
# ==========================================================
ols_fruit = run_ols(df, "WTP Fruit scales 1 to 7", predictors)
ols_veg   = run_ols(df, "WTP vegetables scales 1 to 7", predictors)
logit_gen, scaler_gen = run_logistic(df, "WTP in general yes or no", predictors)

# ==========================================================
# 9. COEFFICIENT PLOTS FOR EACH MODEL
# ==========================================================
def plot_coefficients_colored(values, title, colors):
    plt.figure(figsize=(7,5))
    bars = plt.barh(values.index, values.values, color=colors[:len(values)])
    plt.title(title)
    plt.xlabel("Coefficient Value")
    plt.tight_layout()
    plt.show()

color_palette = ["#0ABAB5","#56DFCF","#ADEED9","#FFEDF3"]

# OLS Raw Coeff
plot_coefficients_colored(ols_fruit.params.drop("const"), "Coefficient Plot – WTP Fruit (OLS)", color_palette)
plot_coefficients_colored(ols_veg.params.drop("const"), "Coefficient Plot – WTP Vegetable (OLS)", color_palette)

# Logistic Coeff (Statsmodels)
logit_coeff = logit_gen.params[1:]  # exclude intercept
logit_coeff.index = predictors

plot_coefficients_colored(
    logit_coeff,
    "Coefficient Plot – WTP General (Logistic)",
    color_palette
)

# ==========================================================
# 10. STANDARDIZED COEFFICIENTS FOR COMPARISON
# ==========================================================
# Standardized betas cho OLS
beta_fruit = standardized_beta_ols(df, "WTP Fruit scales 1 to 7", predictors)
beta_veg   = standardized_beta_ols(df, "WTP vegetables scales 1 to 7", predictors)

# Logistic: lấy hệ số từ statsmodels
# Bỏ intercept và chuẩn hóa index
logit_coeff_std = logit_gen.params[1:]   # exclude intercept
logit_coeff_std.index = predictors

# only keep EnvConcern and PsychAttitude
comparison_df = pd.DataFrame({
    "Fruit": beta_fruit[["EnvConcern","PsychAttitude"]],
    "Vegetable": beta_veg[["EnvConcern","PsychAttitude"]],
    "General": logit_coeff_std[["EnvConcern","PsychAttitude"]]
})

print("\n===== Standardized Coefficients Comparison =====")
print(comparison_df)

# ==========================================================
# 11. GROUPED BAR CHART (COMBINED)
# ==========================================================
comparison_df.plot(kind="bar", figsize=(10,6), color=["#0ABAB5","#56DFCF","#ADEED9"])
plt.title("Grouped Bar Chart – Standardized Coefficient Comparison")
plt.xlabel("Constructs")
plt.ylabel("Standardized Coefficients (β or Log-Odds)")
plt.xticks(rotation=0)
plt.legend(title="WTP Type")
plt.tight_layout()
plt.show()